{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Whr2w8Ywczon"
   },
   "source": [
    "# Cleaning and Validating Healthcare Data Using Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hgqn00Zlczop"
   },
   "source": [
    "Time estimate: **30** minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1yR3JWYwczop"
   },
   "source": [
    "## Objectives\n",
    "\n",
    "After completing this lab, you will be able to:\n",
    "\n",
    " - Identify and handle common data quality issues including missing values, duplicates, inconsistent entries, and outliers.\n",
    " - Remove Personally Identifiable Information (PII) to ensure data privacy compliance with HIPAA and GDPR.\n",
    " - Apply data transformation techniques including standardization, normalization, and encoding.\n",
    "\n",
    "\n",
    "## What you will do in this lab\n",
    "\n",
    "In this hands-on lab, you will work with real-world healthcare data that contains typical quality issues found in medical datasets. You'll learn to clean and prepare this data for machine learning applications while maintaining patient privacy.\n",
    "\n",
    "You will:\n",
    "\n",
    "- Explore and identify data quality issues in a healthcare dataset\n",
    "- Remove sensitive patient information (PII) to comply with privacy regulations\n",
    "- Handle missing values using appropriate imputation strategies\n",
    "- Standardize inconsistent categorical data and mixed units\n",
    "- Detect and handle outliers using statistical methods\n",
    "- Engineer meaningful features such as BMI and temporal indicators\n",
    "- Encode categorical variables and scale numeric features for ML readiness\n",
    "\n",
    "## Overview\n",
    "\n",
    "Data preprocessing is a critical step in any machine learning pipeline, but it becomes especially important in healthcare applications where data quality directly impacts patient outcomes. Raw healthcare data often contains inconsistencies, missing values, mixed formats, and privacy-sensitive information that must be carefully addressed before building predictive models.\n",
    "\n",
    "In this lab, you'll work with a synthetic healthcare dataset that simulates real-world challenges such as inconsistent gender labels (M/Male/F/Female), mixed measurement units (lbs/kg), various date formats, and missing diagnostic information. You'll learn systematic approaches to clean this data while maintaining its utility for analysis.\n",
    "\n",
    "The preprocessing pipeline you'll build follows industry best practices: first removing PII for privacy, then addressing data quality issues, followed by feature engineering to create more informative variables, and finally transforming the data into a format suitable for machine learning algorithms. These skills are directly applicable to real healthcare analytics projects where clean, privacy-compliant data is essential.\n",
    "\n",
    "By the end of this lab, you'll have a complete understanding of how to transform messy healthcare data into a clean, standardized dataset ready for predictive modeling tasks such as risk assessment or disease diagnosis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lA_QRXfGczoq"
   },
   "source": [
    "## About the dataset\n",
    "\n",
    "This lab uses a synthetic healthcare dataset designed to simulate real-world medical data challenges.\n",
    "\n",
    "### Dataset overview\n",
    "\n",
    "The dataset contains patient health records including demographics, vital measurements, diagnostic information, and risk indicators. This data simulates what you might encounter in electronic health records (EHR) systems, complete with the messiness and inconsistencies typical of real medical data. The dataset includes 200 patient records with intentionally introduced quality issues such as missing values, inconsistent formatting, mixed units, and duplicate entries to provide realistic preprocessing practice.\n",
    "\n",
    "### Column descriptions\n",
    "\n",
    "1. **Patient_ID** - Unique identifier for each patient (e.g., P016, P_new_126)\n",
    "2. **Age** - Age of the patient in years (may contain missing values or outliers)\n",
    "3. **Gender** - Gender of the patient (inconsistent formats: M, Male, F, Female, Other)\n",
    "4. **Ethnicity** - Ethnic background of the patient (Asian, African, Caucasian, Hispanic with inconsistent capitalization)\n",
    "5. **Weight** - Weight of the patient in mixed units (kg or lbs, e.g., 70, 150lbs)\n",
    "6. **Height_cm** - Height of the patient in centimeters (numeric values)\n",
    "7. **Diagnosis_Date** - Date when diagnosis was made (multiple date formats: YYYY-MM-DD, DD/MM/YYYY)\n",
    "8. **Diagnosis_Code** - Medical diagnosis code or abbreviation (DEP=Depression, OCD=Obsessive Compulsive Disorder, ANX=Anxiety, ANXITY=typo for Anxiety)\n",
    "9. **Glucose_mg_dL** - Blood glucose level in mg/dL (may indicate diabetes risk)\n",
    "10. **Risk** - Binary risk indicator (0 = low risk, 1 = high risk for adverse health outcomes)\n",
    "11. **Patient_Name** - Full name of the patient (PII - to be removed)\n",
    "12. **EmailID** - Email address of the patient (PII - to be removed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D6ywsdmUczor"
   },
   "source": [
    "## Setup\n",
    "\n",
    "### Installing required libraries\n",
    "\n",
    "The following libraries are required to run this lab. Pandas will be used for data manipulation, NumPy for numerical operations, SciPy for statistical functions, and Scikit-learn for preprocessing utilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "p1X25911czor"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\sugne\\anaconda3\\envs\\retinanet\\lib\\site-packages (1.1.5)\n",
      "Requirement already satisfied: numpy>=1.15.4 in c:\\users\\sugne\\anaconda3\\envs\\retinanet\\lib\\site-packages (from pandas) (1.19.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\sugne\\anaconda3\\envs\\retinanet\\lib\\site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\sugne\\anaconda3\\envs\\retinanet\\lib\\site-packages (from pandas) (2020.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\sugne\\anaconda3\\envs\\retinanet\\lib\\site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\sugne\\anaconda3\\envs\\retinanet\\lib\\site-packages (1.19.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\sugne\\anaconda3\\envs\\retinanet\\lib\\site-packages (1.5.0)\n",
      "Requirement already satisfied: numpy>=1.14.5 in c:\\users\\sugne\\anaconda3\\envs\\retinanet\\lib\\site-packages (from scipy) (1.19.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\sugne\\anaconda3\\envs\\retinanet\\lib\\site-packages (0.23.1)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\users\\sugne\\anaconda3\\envs\\retinanet\\lib\\site-packages (from scikit-learn) (1.5.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\sugne\\anaconda3\\envs\\retinanet\\lib\\site-packages (from scikit-learn) (2.1.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\sugne\\anaconda3\\envs\\retinanet\\lib\\site-packages (from scikit-learn) (1.19.3)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\sugne\\anaconda3\\envs\\retinanet\\lib\\site-packages (from scikit-learn) (0.16.0)\n"
     ]
    }
   ],
   "source": [
    "# Install the libraries required for this lab\n",
    "!pip install pandas\n",
    "!pip install numpy\n",
    "!pip install scipy\n",
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "zgTh_T_Uczos"
   },
   "outputs": [],
   "source": [
    "# Optional: suppress warnings for cleaner output\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MR4gEjHHczos"
   },
   "source": [
    "### Importing required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "3lo9B80Uczos"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries imported successfully!\n",
      "Ready to begin healthcare data preprocessing.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd   # For data loading, manipulation, cleaning, and saving (DataFrame operations)\n",
    "import numpy as np    # For numerical operations, array handling, and missing value operations\n",
    "import re             # For regular expression pattern matching in text processing\n",
    "\n",
    "from datetime import datetime, timedelta  # For parsing and manipulating date/time values\n",
    "import random  # For generating random values during data exploration\n",
    "\n",
    "from scipy import stats  # For statistical functions like z-score for outlier detection\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\n",
    "# StandardScaler: standardizes features (mean=0, std=1) for ML algorithms\n",
    "# MinMaxScaler: scales features to a fixed range (typically 0-1)\n",
    "# OneHotEncoder: converts categorical features into binary indicator variables\n",
    "\n",
    "print(\"All libraries imported successfully!\")\n",
    "print(\"Ready to begin healthcare data preprocessing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u5IhflPxczot"
   },
   "source": [
    "## Step 1: Load and explore the raw data\n",
    "\n",
    "Before cleaning data, it's essential to understand what you're working with. In this step, you'll load the healthcare dataset and perform an initial exploration to identify data quality issues. This exploration phase helps you make informed decisions about which preprocessing techniques to apply."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "DB1zYpCcczot"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows of the dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient_ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Height_cm</th>\n",
       "      <th>Diagnosis_Date</th>\n",
       "      <th>Diagnosis_Code</th>\n",
       "      <th>Glucose_mg_dL</th>\n",
       "      <th>Risk</th>\n",
       "      <th>Patient_Name</th>\n",
       "      <th>EmailID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P_new_63</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>asian</td>\n",
       "      <td>NaN</td>\n",
       "      <td>175.0</td>\n",
       "      <td>2021-10-21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>140.0</td>\n",
       "      <td>0</td>\n",
       "      <td>David Jones</td>\n",
       "      <td>kurt31@example.org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P016</td>\n",
       "      <td>50.0</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>165.0</td>\n",
       "      <td>2020-05-20</td>\n",
       "      <td>DEP</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Cristina White</td>\n",
       "      <td>parkerjennifer@example.org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P006</td>\n",
       "      <td>25.0</td>\n",
       "      <td>F</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15/06/2021</td>\n",
       "      <td>OCD</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Laura Bates</td>\n",
       "      <td>sean22@example.net</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P_new_126</td>\n",
       "      <td>34.0</td>\n",
       "      <td>M</td>\n",
       "      <td>asian</td>\n",
       "      <td>70</td>\n",
       "      <td>160.0</td>\n",
       "      <td>2016-10-19</td>\n",
       "      <td>ocd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Rebecca Smith</td>\n",
       "      <td>johnmcclure@example.net</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P_new_96</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Asian</td>\n",
       "      <td>70</td>\n",
       "      <td>180.0</td>\n",
       "      <td>2016-02-09</td>\n",
       "      <td>ANXITY</td>\n",
       "      <td>140.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Brittany Wise</td>\n",
       "      <td>nholloway@example.net</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Patient_ID   Age Gender  Ethnicity Weight  Height_cm Diagnosis_Date  \\\n",
       "0   P_new_63   NaN    NaN      asian    NaN      175.0     2021-10-21   \n",
       "1       P016  50.0      M        NaN    NaN      165.0     2020-05-20   \n",
       "2       P006  25.0      F  Caucasian    NaN        NaN     15/06/2021   \n",
       "3  P_new_126  34.0      M      asian     70      160.0     2016-10-19   \n",
       "4   P_new_96  25.0    NaN      Asian     70      180.0     2016-02-09   \n",
       "\n",
       "  Diagnosis_Code  Glucose_mg_dL  Risk    Patient_Name  \\\n",
       "0            NaN          140.0     0     David Jones   \n",
       "1            DEP          100.0     0  Cristina White   \n",
       "2            OCD          110.0     0     Laura Bates   \n",
       "3            ocd            NaN     1   Rebecca Smith   \n",
       "4         ANXITY          140.0     0   Brittany Wise   \n",
       "\n",
       "                      EmailID  \n",
       "0          kurt31@example.org  \n",
       "1  parkerjennifer@example.org  \n",
       "2          sean22@example.net  \n",
       "3     johnmcclure@example.net  \n",
       "4       nholloway@example.net  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the raw healthcare data from CSV file\n",
    "df = pd.read_csv(\"https://foundations-of-healthcare-data-analytics-4e579d.gitlab.io/labs/Cleaning_and_Validating_Healthcare_Data_Using_Python/raw_data.csv\")\n",
    "\n",
    "# Display the first few rows to get an initial sense of the data\n",
    "print(\"First 5 rows of the dataset:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F4frA4GKczot"
   },
   "source": [
    "## Step 2: Understand data quality issues\n",
    "\n",
    "Real-world healthcare data commonly suffers from four main quality issues:\n",
    "\n",
    "1. **Missing data**: Important fields left blank or null\n",
    "2. **Duplicates**: Identical records appearing multiple times\n",
    "3. **Inconsistent entries**: Same category with different labels (e.g., M vs Male)\n",
    "4. **Outliers**: Extreme or impossible values (e.g., Age=200, Glucose=500)\n",
    "\n",
    "Let's systematically identify these issues in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "fs2fuNMmczot"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset dimensions:\n",
      "Number of rows: 200\n",
      "Number of columns: 12\n",
      "\n",
      "Column names and data types:\n",
      "Patient_ID         object\n",
      "Age               float64\n",
      "Gender             object\n",
      "Ethnicity          object\n",
      "Weight             object\n",
      "Height_cm         float64\n",
      "Diagnosis_Date     object\n",
      "Diagnosis_Code     object\n",
      "Glucose_mg_dL     float64\n",
      "Risk                int64\n",
      "Patient_Name       object\n",
      "EmailID            object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Basic dataset structure\n",
    "print(\"Dataset dimensions:\")\n",
    "print(f\"Number of rows: {df.shape[0]}\")\n",
    "print(f\"Number of columns: {df.shape[1]}\")\n",
    "print(\"\\nColumn names and data types:\")\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "BLSeuJMqczot"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values per column:\n",
      "Patient_ID         0\n",
      "Age               28\n",
      "Gender            38\n",
      "Ethnicity         35\n",
      "Weight            44\n",
      "Height_cm         40\n",
      "Diagnosis_Date    10\n",
      "Diagnosis_Code    33\n",
      "Glucose_mg_dL     42\n",
      "Risk               0\n",
      "Patient_Name       0\n",
      "EmailID            0\n",
      "dtype: int64\n",
      "\n",
      "Percentage of missing values:\n",
      "Patient_ID         0.0\n",
      "Age               14.0\n",
      "Gender            19.0\n",
      "Ethnicity         17.5\n",
      "Weight            22.0\n",
      "Height_cm         20.0\n",
      "Diagnosis_Date     5.0\n",
      "Diagnosis_Code    16.5\n",
      "Glucose_mg_dL     21.0\n",
      "Risk               0.0\n",
      "Patient_Name       0.0\n",
      "EmailID            0.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(\"\\nMissing values per column:\")\n",
    "print(df.isnull().sum())\n",
    "print(\"\\nPercentage of missing values:\")\n",
    "print((df.isnull().sum() / len(df) * 100).round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "p5YmdvKyczou"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of duplicate rows: 0\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicate rows\n",
    "dup_rows = df.duplicated(keep=False)\n",
    "print(f\"\\nNumber of duplicate rows: {dup_rows.sum()}\")\n",
    "if dup_rows.any():\n",
    "    display(df[dup_rows])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "QJYw90baczou"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unique values in Gender column:\n",
      "[nan 'M' 'F' 'Male' 'Female' 'Other']\n",
      "\n",
      "Unique values in Ethnicity column:\n",
      "['asian' nan 'Caucasian' 'Asian' 'African' 'Hispanic' 'caucasian']\n",
      "\n",
      "Unique values in Diagnosis_Code column:\n",
      "[nan 'DEP' 'OCD' 'ocd' 'ANXITY' 'ANX']\n"
     ]
    }
   ],
   "source": [
    "# Identify inconsistent categorical entries\n",
    "print(\"\\nUnique values in Gender column:\")\n",
    "print(df['Gender'].unique())\n",
    "print(\"\\nUnique values in Ethnicity column:\")\n",
    "print(df['Ethnicity'].unique())\n",
    "print(\"\\nUnique values in Diagnosis_Code column:\")\n",
    "print(df['Diagnosis_Code'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Q0NBklBPczou"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unique Weight values (showing mixed units):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([nan, '70', '110', '150lbs', '90', '75', '160lbs', '80'],\n",
       "      dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check for mixed units in Weight column\n",
    "print(\"\\nUnique Weight values (showing mixed units):\")\n",
    "display(df['Weight'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "gQR-qZIeczou"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Statistical summary of numeric columns:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Glucose_mg_dL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>172.000000</td>\n",
       "      <td>158.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>70.087209</td>\n",
       "      <td>220.981013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>62.340026</td>\n",
       "      <td>177.443324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>25.000000</td>\n",
       "      <td>85.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>34.000000</td>\n",
       "      <td>90.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>45.000000</td>\n",
       "      <td>110.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>60.000000</td>\n",
       "      <td>500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>200.000000</td>\n",
       "      <td>500.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Age  Glucose_mg_dL\n",
       "count  172.000000     158.000000\n",
       "mean    70.087209     220.981013\n",
       "std     62.340026     177.443324\n",
       "min     25.000000      85.000000\n",
       "25%     34.000000      90.000000\n",
       "50%     45.000000     110.000000\n",
       "75%     60.000000     500.000000\n",
       "max    200.000000     500.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Statistical summary to identify potential outliers\n",
    "print(\"\\nStatistical summary of numeric columns:\")\n",
    "display(df[['Age', 'Glucose_mg_dL']].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Nu9ZJ9uiczou"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample of Diagnosis_Date values (showing mixed formats):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "95     2023-03-23\n",
       "15     10/01/2018\n",
       "30     2022-01-10\n",
       "158    15/06/2021\n",
       "128    19/03/2019\n",
       "115    25/02/2016\n",
       "69     2018-03-31\n",
       "170    2020-02-04\n",
       "174    26/09/2021\n",
       "45     2020-12-31\n",
       "Name: Diagnosis_Date, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check date format inconsistencies\n",
    "print(\"\\nSample of Diagnosis_Date values (showing mixed formats):\")\n",
    "display(df['Diagnosis_Date'].sample(10, random_state=42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "-MATK1fSczou"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Risk value distribution:\n",
      "0    107\n",
      "1     93\n",
      "Name: Risk, dtype: int64\n",
      "\n",
      "Risk percentage distribution:\n",
      "0    53.5\n",
      "1    46.5\n",
      "Name: Risk, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Check class balance for the target variable\n",
    "print(\"\\nRisk value distribution:\")\n",
    "print(df['Risk'].value_counts())\n",
    "print(\"\\nRisk percentage distribution:\")\n",
    "print((df['Risk'].value_counts() / len(df) * 100).round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9jyBp_Soczou"
   },
   "source": [
    "## Step 3: Detect outliers using statistical methods\n",
    "\n",
    "Outliers can significantly impact machine learning models. You'll use two common statistical methods to detect them:\n",
    "\n",
    "### Interquartile Range (IQR) method\n",
    "- **Formula**: IQR = Q3 − Q1 (difference between 75th and 25th percentiles)\n",
    "- **Outlier definition**: Values below Q1 − 1.5 × IQR or above Q3 + 1.5 × IQR\n",
    "- **Best for**: Non-normally distributed data (robust against skewness)\n",
    "\n",
    "### Z-Score method\n",
    "- **Formula**: Z = (Value − Mean) / Standard Deviation\n",
    "- **Outlier definition**: |Z-score| > 3 (more than 3 standard deviations from mean)\n",
    "- **Best for**: Normally distributed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "PEsAcOSkczou"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age outliers (IQR method):\n",
      "Found 31 outliers in Age\n",
      "Outlier values: [200.]\n",
      "\n",
      "Glucose outliers (IQR method):\n",
      "Found 0 outliers in Glucose_mg_dL\n"
     ]
    }
   ],
   "source": [
    "# Function to detect outliers using IQR method\n",
    "def iqr_outliers(series):\n",
    "    \"\"\"\n",
    "    Detect outliers using the Interquartile Range (IQR) method.\n",
    "\n",
    "    Parameters:\n",
    "    series: pandas Series - numeric column to check for outliers\n",
    "\n",
    "    Returns:\n",
    "    pandas Series - containing only the outlier values\n",
    "    \"\"\"\n",
    "    q1 = series.quantile(0.25)  # 25th percentile\n",
    "    q3 = series.quantile(0.75)  # 75th percentile\n",
    "    iqr = q3 - q1                # Interquartile range\n",
    "    lower_bound = q1 - 1.5 * iqr\n",
    "    upper_bound = q3 + 1.5 * iqr\n",
    "    return series[(series < lower_bound) | (series > upper_bound)]\n",
    "\n",
    "# Detect outliers in Age\n",
    "print(\"Age outliers (IQR method):\")\n",
    "age_outliers = iqr_outliers(df['Age'].dropna())\n",
    "print(f\"Found {len(age_outliers)} outliers in Age\")\n",
    "print(f\"Outlier values: {age_outliers.unique()}\")\n",
    "\n",
    "# Detect outliers in Glucose\n",
    "print(\"\\nGlucose outliers (IQR method):\")\n",
    "glucose_outliers = iqr_outliers(df['Glucose_mg_dL'].dropna())\n",
    "print(f\"Found {len(glucose_outliers)} outliers in Glucose_mg_dL\")\n",
    "if len(glucose_outliers) > 0:\n",
    "    print(f\"Outlier values: {glucose_outliers.unique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cMcHf6gCczov"
   },
   "source": [
    "## Step 4: Create a clean copy and remove PII\n",
    "\n",
    "Privacy protection is paramount in healthcare data. **Personally Identifiable Information (PII)** includes any data that can directly or indirectly identify an individual. Common PII in healthcare includes:\n",
    "\n",
    "- **Direct identifiers**: Patient names, email addresses, phone numbers, addresses\n",
    "- **Semi-identifiers**: Patient IDs (can be kept if properly anonymized)\n",
    "- **Sensitive dates**: Birth dates, exact diagnosis dates (often generalized)\n",
    "\n",
    "Regulations like **HIPAA** (USA) and **GDPR** (Europe) require removing or anonymizing PII before data analysis or sharing.\n",
    "\n",
    "You'll create a copy of the original data (to preserve the raw data) and remove PII columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "tQYRScU9czov"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working copy created. Original data preserved.\n"
     ]
    }
   ],
   "source": [
    "# Create a working copy - keep original data untouched for reference\n",
    "df_clean = df.copy()\n",
    "print(\"Working copy created. Original data preserved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "TAgILu7eczov"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing PII columns: ['Patient_Name', 'EmailID']\n",
      "\n",
      "Columns after removing PII:\n",
      "['Patient_ID', 'Age', 'Gender', 'Ethnicity', 'Weight', 'Height_cm', 'Diagnosis_Date', 'Diagnosis_Code', 'Glucose_mg_dL', 'Risk']\n",
      "\n",
      "Reduced from 12 to 10 columns\n"
     ]
    }
   ],
   "source": [
    "# Identify and remove PII columns\n",
    "pii_columns = ['Patient_Name', 'EmailID']\n",
    "print(f\"Removing PII columns: {pii_columns}\")\n",
    "\n",
    "df_clean = df_clean.drop(columns=pii_columns, errors='ignore')\n",
    "\n",
    "print(\"\\nColumns after removing PII:\")\n",
    "print(df_clean.columns.tolist())\n",
    "print(f\"\\nReduced from {len(df.columns)} to {len(df_clean.columns)} columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5wwsKzf7czov"
   },
   "source": [
    "## Step 5: Remove duplicate rows\n",
    "\n",
    "Duplicate records can occur due to data entry errors, system glitches, or merging datasets. They can:\n",
    "- Bias analysis by overrepresenting certain patients\n",
    "- Inflate dataset size artificially\n",
    "- Cause data leakage in train-test splits\n",
    "\n",
    "You'll identify and remove exact duplicate rows, keeping only the first occurrence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "Wxtw2s-Zczov"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows before deduplication: 200\n",
      "Duplicate rows found: 2\n",
      "Rows after deduplication: 198\n",
      "Rows removed: 2\n"
     ]
    }
   ],
   "source": [
    "# Count duplicates before removal\n",
    "duplicates_before = df_clean.duplicated().sum()\n",
    "rows_before = len(df_clean)\n",
    "\n",
    "# Remove exact duplicate rows (keep first occurrence)\n",
    "df_clean = df_clean.drop_duplicates(keep='first')\n",
    "\n",
    "# Report results\n",
    "rows_after = len(df_clean)\n",
    "print(f\"Rows before deduplication: {rows_before}\")\n",
    "print(f\"Duplicate rows found: {duplicates_before}\")\n",
    "print(f\"Rows after deduplication: {rows_after}\")\n",
    "print(f\"Rows removed: {rows_before - rows_after}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eU_OLZsaczov"
   },
   "source": [
    "## Step 6: Standardize inconsistent categorical variables\n",
    "\n",
    "Inconsistent categorical data is common in healthcare due to:\n",
    "- Multiple data entry personnel with different conventions\n",
    "- Data merging from different systems\n",
    "- Typos and abbreviations\n",
    "\n",
    "You need to standardize:\n",
    "- **Gender**: Convert M/Male/m → 'Male', F/Female/f → 'Female'\n",
    "- **Ethnicity**: Standardize capitalization (asian/Asian/ASIAN → 'Asian')\n",
    "- **Diagnosis_Code**: Fix typos and standardize (OCD/ocd → 'OCD', ANXITY → 'ANX')\n",
    "\n",
    "This ensures categorical data is **clean, consistent, and machine-readable**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "tIoRy300czov"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before standardization - Gender unique values:\n",
      "M         46\n",
      "F         39\n",
      "NaN       38\n",
      "Female    35\n",
      "Male      33\n",
      "Other      7\n",
      "Name: Gender, dtype: int64\n",
      "\n",
      "After standardization - Gender unique values:\n",
      "Male      79\n",
      "Female    74\n",
      "NaN       38\n",
      "Other      7\n",
      "Name: Gender, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Standardize Gender column\n",
    "print(\"Before standardization - Gender unique values:\")\n",
    "print(df_clean['Gender'].value_counts(dropna=False))\n",
    "\n",
    "# Convert to lowercase and strip whitespace for consistent matching\n",
    "df_clean['Gender'] = df_clean['Gender'].astype(str).str.strip().str.lower()\n",
    "\n",
    "# Define mapping for known variations\n",
    "gender_map = {\n",
    "    'male': 'Male', 'm': 'Male',\n",
    "    'female': 'Female', 'f': 'Female',\n",
    "    'other': 'Other',\n",
    "    'nan': np.nan, 'none': np.nan\n",
    "}\n",
    "\n",
    "# Apply mapping\n",
    "df_clean['Gender'] = df_clean['Gender'].replace({'nan': np.nan})\n",
    "df_clean['Gender'] = df_clean['Gender'].map(\n",
    "    lambda x: gender_map.get(x, x.capitalize() if pd.notna(x) else x)\n",
    ")\n",
    "\n",
    "print(\"\\nAfter standardization - Gender unique values:\")\n",
    "print(df_clean['Gender'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "ZZyIqYhwczov"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before standardization - Ethnicity unique values:\n",
      "Asian        41\n",
      "NaN          35\n",
      "asian        34\n",
      "African      32\n",
      "Hispanic     31\n",
      "Caucasian    18\n",
      "caucasian     7\n",
      "Name: Ethnicity, dtype: int64\n",
      "\n",
      "After standardization - Ethnicity unique values:\n",
      "Asian        75\n",
      "NaN          35\n",
      "African      32\n",
      "Hispanic     31\n",
      "Caucasian    25\n",
      "Name: Ethnicity, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Standardize Ethnicity column\n",
    "print(\"Before standardization - Ethnicity unique values:\")\n",
    "print(df_clean['Ethnicity'].value_counts(dropna=False))\n",
    "\n",
    "# Standardize capitalization\n",
    "df_clean['Ethnicity'] = df_clean['Ethnicity'].astype(str).str.strip()\n",
    "df_clean['Ethnicity'] = df_clean['Ethnicity'].replace({'nan': np.nan})\n",
    "df_clean['Ethnicity'] = df_clean['Ethnicity'].where(\n",
    "    df_clean['Ethnicity'].isna(),\n",
    "    df_clean['Ethnicity'].str.capitalize()\n",
    ")\n",
    "\n",
    "print(\"\\nAfter standardization - Ethnicity unique values:\")\n",
    "print(df_clean['Ethnicity'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "7J3jSKIlczow"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before standardization - Diagnosis_Code unique values:\n",
      "OCD       40\n",
      "DEP       39\n",
      "ocd       35\n",
      "NaN       32\n",
      "ANX       31\n",
      "ANXITY    21\n",
      "Name: Diagnosis_Code, dtype: int64\n",
      "\n",
      "After standardization - Diagnosis_Code unique values:\n",
      "OCD    75\n",
      "ANX    52\n",
      "DEP    39\n",
      "NaN    32\n",
      "Name: Diagnosis_Code, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Standardize Diagnosis_Code column\n",
    "print(\"Before standardization - Diagnosis_Code unique values:\")\n",
    "print(df_clean['Diagnosis_Code'].value_counts(dropna=False))\n",
    "\n",
    "# Convert to uppercase and fix common typos\n",
    "df_clean['Diagnosis_Code'] = df_clean['Diagnosis_Code'].astype(str).str.strip().str.upper()\n",
    "df_clean['Diagnosis_Code'] = df_clean['Diagnosis_Code'].replace({\n",
    "    'NAN': np.nan,\n",
    "    'ANXITY': 'ANX',  # Fix typo\n",
    "    'OCD.': 'OCD'      # Remove trailing period\n",
    "})\n",
    "\n",
    "print(\"\\nAfter standardization - Diagnosis_Code unique values:\")\n",
    "print(df_clean['Diagnosis_Code'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "FPOkjl_5czow"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing categorical values filled with 'Unknown'\n",
      "\n",
      "Final categorical value counts:\n",
      "\n",
      "Gender:\n",
      "Male       79\n",
      "Female     74\n",
      "Unknown    38\n",
      "Other       7\n",
      "Name: Gender, dtype: int64\n",
      "\n",
      "Ethnicity:\n",
      "Asian        75\n",
      "Unknown      35\n",
      "African      32\n",
      "Hispanic     31\n",
      "Caucasian    25\n",
      "Name: Ethnicity, dtype: int64\n",
      "\n",
      "Diagnosis_Code:\n",
      "OCD        75\n",
      "ANX        52\n",
      "DEP        39\n",
      "Unknown    32\n",
      "Name: Diagnosis_Code, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Fill missing categorical values with 'Unknown'\n",
    "df_clean['Gender'] = df_clean['Gender'].fillna('Unknown')\n",
    "df_clean['Ethnicity'] = df_clean['Ethnicity'].fillna('Unknown')\n",
    "df_clean['Diagnosis_Code'] = df_clean['Diagnosis_Code'].fillna('Unknown')\n",
    "\n",
    "print(\"Missing categorical values filled with 'Unknown'\")\n",
    "print(\"\\nFinal categorical value counts:\")\n",
    "print(\"\\nGender:\")\n",
    "print(df_clean['Gender'].value_counts())\n",
    "print(\"\\nEthnicity:\")\n",
    "print(df_clean['Ethnicity'].value_counts())\n",
    "print(\"\\nDiagnosis_Code:\")\n",
    "print(df_clean['Diagnosis_Code'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lcKcgKUQczow"
   },
   "source": [
    "## Step 7: Normalize mixed units and engineer BMI feature\n",
    "\n",
    "Healthcare data often contains mixed measurement units due to different countries or systems using different standards (metric vs imperial). You need to:\n",
    "\n",
    "1. **Normalize Weight**: Convert all weights to kg (from mixed kg and lbs)\n",
    "2. **Convert Height**: Convert cm to meters for BMI calculation\n",
    "3. **Engineer BMI**: Body Mass Index is a clinically important derived feature\n",
    "\n",
    "**BMI Formula**: BMI = Weight(kg) / Height(m)²\n",
    "\n",
    "**BMI Categories**:\n",
    "- Underweight: < 18.5\n",
    "- Normal: 18.5 - 24.9\n",
    "- Overweight: 25 - 29.9\n",
    "- Obese: ≥ 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "Q4fSJvTTczow"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight conversion examples:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Weight</th>\n",
       "      <th>Weight_kg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>70.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70</td>\n",
       "      <td>70.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>110</td>\n",
       "      <td>110.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>150lbs</td>\n",
       "      <td>68.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>150lbs</td>\n",
       "      <td>68.04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Weight  Weight_kg\n",
       "0     NaN        NaN\n",
       "1     NaN        NaN\n",
       "2     NaN        NaN\n",
       "3      70      70.00\n",
       "4      70      70.00\n",
       "5     110     110.00\n",
       "6     NaN        NaN\n",
       "7     NaN        NaN\n",
       "8  150lbs      68.04\n",
       "9  150lbs      68.04"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Function to convert weight to kg (handles both numeric kg and string 'lbs' format)\n",
    "def weight_to_kg(x):\n",
    "    \"\"\"\n",
    "    Convert weight to kilograms.\n",
    "    Handles numeric values (assumed kg) and strings with 'lbs' suffix.\n",
    "\n",
    "    Examples:\n",
    "    70 -> 70.0 kg\n",
    "    '150lbs' -> 68.04 kg\n",
    "    '150 lbs' -> 68.04 kg\n",
    "    \"\"\"\n",
    "    if pd.isna(x):\n",
    "        return np.nan\n",
    "\n",
    "    # If already numeric, assume it's in kg\n",
    "    if isinstance(x, (int, float, np.integer, np.floating)):\n",
    "        return float(x)\n",
    "\n",
    "    # Handle string values\n",
    "    s = str(x).strip().lower()\n",
    "\n",
    "    # Check for lbs pattern (e.g., '150lbs' or '150 lbs')\n",
    "    match = re.match(r'^\\s*([0-9]+(?:\\.[0-9]+)?)\\s*lbs?\\s*$', s)\n",
    "    if match:\n",
    "        lbs = float(match.group(1))\n",
    "        return round(lbs * 0.45359237, 2)  # Convert lbs to kg\n",
    "\n",
    "    # Try to parse as numeric (assume kg)\n",
    "    try:\n",
    "        return float(s)\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "# Apply weight conversion\n",
    "df_clean['Weight_kg'] = df_clean['Weight'].apply(weight_to_kg)\n",
    "\n",
    "print(\"Weight conversion examples:\")\n",
    "display(df_clean[['Weight', 'Weight_kg']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "uFk1xjVJczow"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Height converted from cm to meters\n"
     ]
    }
   ],
   "source": [
    "# Convert height from cm to meters\n",
    "df_clean['Height_cm'] = pd.to_numeric(df_clean['Height_cm'], errors='coerce')\n",
    "df_clean['Height_m'] = df_clean['Height_cm'] / 100.0\n",
    "\n",
    "print(\"Height converted from cm to meters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "qoMr2V-sczow"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BMI calculated successfully\n",
      "\n",
      "Sample of engineered features:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Weight</th>\n",
       "      <th>Weight_kg</th>\n",
       "      <th>Height_cm</th>\n",
       "      <th>Height_m</th>\n",
       "      <th>BMI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>175.0</td>\n",
       "      <td>1.75</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>165.0</td>\n",
       "      <td>1.65</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>70.00</td>\n",
       "      <td>160.0</td>\n",
       "      <td>1.60</td>\n",
       "      <td>27.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70</td>\n",
       "      <td>70.00</td>\n",
       "      <td>180.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>21.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>110</td>\n",
       "      <td>110.00</td>\n",
       "      <td>180.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>33.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>175.0</td>\n",
       "      <td>1.75</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>175.0</td>\n",
       "      <td>1.75</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>150lbs</td>\n",
       "      <td>68.04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>150lbs</td>\n",
       "      <td>68.04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Weight  Weight_kg  Height_cm  Height_m    BMI\n",
       "0     NaN        NaN      175.0      1.75    NaN\n",
       "1     NaN        NaN      165.0      1.65    NaN\n",
       "2     NaN        NaN        NaN       NaN    NaN\n",
       "3      70      70.00      160.0      1.60  27.34\n",
       "4      70      70.00      180.0      1.80  21.60\n",
       "5     110     110.00      180.0      1.80  33.95\n",
       "6     NaN        NaN      175.0      1.75    NaN\n",
       "7     NaN        NaN      175.0      1.75    NaN\n",
       "8  150lbs      68.04        NaN       NaN    NaN\n",
       "9  150lbs      68.04        NaN       NaN    NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate BMI (Body Mass Index)\n",
    "df_clean['BMI'] = df_clean.apply(\n",
    "    lambda row: round(row['Weight_kg'] / (row['Height_m'] ** 2), 2)\n",
    "    if pd.notna(row['Weight_kg']) and pd.notna(row['Height_m']) and row['Height_m'] > 0\n",
    "    else np.nan,\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "print(\"BMI calculated successfully\")\n",
    "print(\"\\nSample of engineered features:\")\n",
    "display(df_clean[['Weight', 'Weight_kg', 'Height_cm', 'Height_m', 'BMI']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5KzsFHBDczow"
   },
   "source": [
    "## Step 8: Handle missing values with imputation\n",
    "\n",
    "Missing values are inevitable in healthcare data. Common causes include:\n",
    "- Tests not performed for all patients\n",
    "- Data entry errors\n",
    "- Equipment failures\n",
    "- Patient privacy restrictions\n",
    "\n",
    "### Why use Median instead of Mean?\n",
    "\n",
    "For healthcare data, **median imputation** is often preferred over mean because:\n",
    "\n",
    "1. **Robust to outliers**: Healthcare data often contains extreme values (very high glucose, unusual ages)\n",
    "2. **Mean is sensitive**: A few extreme values can skew the mean significantly\n",
    "3. **Median represents center**: The middle value of sorted data, unaffected by extremes\n",
    "4. **Preserves distribution**: Better maintains the shape of skewed distributions\n",
    "5. **Simple and fast**: Computationally efficient with no assumptions about distribution\n",
    "\n",
    "You'll impute missing values in numeric columns (Age, Weight_kg, Height_cm, BMI, Glucose_mg_dL) using their respective medians."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "aC7x10Hjczox"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values before imputation:\n",
      "Age              28\n",
      "Weight_kg        43\n",
      "Height_cm        39\n",
      "BMI              75\n",
      "Glucose_mg_dL    42\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check missing values before imputation\n",
    "print(\"Missing values before imputation:\")\n",
    "numeric_cols = ['Age', 'Weight_kg', 'Height_cm', 'BMI', 'Glucose_mg_dL']\n",
    "print(df_clean[numeric_cols].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "hyeXoH0Iczox"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputed Age with median = 45.0\n",
      "Imputed Weight_kg with median = 75.0\n",
      "Imputed Height_cm with median = 165.0\n",
      "Imputed BMI with median = 27.55\n",
      "Imputed Glucose_mg_dL with median = 110.0\n"
     ]
    }
   ],
   "source": [
    "# Median imputation for numeric columns\n",
    "for col in numeric_cols:\n",
    "    median_val = df_clean[col].median()\n",
    "    df_clean[col] = df_clean[col].fillna(median_val)\n",
    "    print(f\"Imputed {col} with median = {median_val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "UBbhCQIVczox"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values after imputation:\n",
      "Age              0\n",
      "Weight_kg        0\n",
      "Height_cm        0\n",
      "BMI              0\n",
      "Glucose_mg_dL    0\n",
      "dtype: int64\n",
      "\n",
      "All numeric missing values successfully imputed!\n"
     ]
    }
   ],
   "source": [
    "# Verify imputation\n",
    "print(\"\\nMissing values after imputation:\")\n",
    "print(df_clean[numeric_cols].isnull().sum())\n",
    "print(\"\\nAll numeric missing values successfully imputed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aDqwHos4czox"
   },
   "source": [
    "## Step 9: Parse dates and engineer temporal features\n",
    "\n",
    "Temporal features can be highly informative in healthcare:\n",
    "- **Diagnosis year**: May reflect changes in diagnostic practices or disease prevalence\n",
    "- **Time since diagnosis**: Important for understanding disease progression\n",
    "- **Seasonal patterns**: Some conditions vary by time of year\n",
    "\n",
    "You'll parse the inconsistent date formats and extract useful temporal features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "jq1Th9sRczox"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date parsing results:\n",
      "Successfully parsed: 188 dates\n",
      "Failed to parse: 10 dates\n",
      "\n",
      "Sample of original vs parsed dates:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Diagnosis_Date</th>\n",
       "      <th>Diagnosis_Date_parsed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-10-21</td>\n",
       "      <td>2021-10-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-05-20</td>\n",
       "      <td>2020-05-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15/06/2021</td>\n",
       "      <td>2021-06-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-10-19</td>\n",
       "      <td>2016-10-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-02-09</td>\n",
       "      <td>2016-02-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2024-05-13</td>\n",
       "      <td>2024-05-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2017-12-31</td>\n",
       "      <td>2017-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2022-12-15</td>\n",
       "      <td>2022-12-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2024-03-04</td>\n",
       "      <td>2024-03-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2022-10-10</td>\n",
       "      <td>2022-10-10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Diagnosis_Date Diagnosis_Date_parsed\n",
       "0     2021-10-21            2021-10-21\n",
       "1     2020-05-20            2020-05-20\n",
       "2     15/06/2021            2021-06-15\n",
       "3     2016-10-19            2016-10-19\n",
       "4     2016-02-09            2016-02-09\n",
       "5     2024-05-13            2024-05-13\n",
       "6     2017-12-31            2017-12-31\n",
       "7     2022-12-15            2022-12-15\n",
       "8     2024-03-04            2024-03-04\n",
       "9     2022-10-10            2022-10-10"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Parse dates with mixed formats (YYYY-MM-DD and DD/MM/YYYY)\n",
    "df_clean['Diagnosis_Date_parsed'] = pd.to_datetime(\n",
    "    df_clean['Diagnosis_Date'],\n",
    "    errors='coerce',  # Convert unparseable dates to NaT (Not a Time)\n",
    "    dayfirst=True     # Assume day comes first in ambiguous formats\n",
    ")\n",
    "\n",
    "print(\"Date parsing results:\")\n",
    "print(f\"Successfully parsed: {df_clean['Diagnosis_Date_parsed'].notna().sum()} dates\")\n",
    "print(f\"Failed to parse: {df_clean['Diagnosis_Date_parsed'].isna().sum()} dates\")\n",
    "\n",
    "print(\"\\nSample of original vs parsed dates:\")\n",
    "display(df_clean[['Diagnosis_Date', 'Diagnosis_Date_parsed']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "OJjcj0T6czoy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reference date for calculating time since diagnosis: 2025-08-20\n",
      "\n",
      "Sample of engineered temporal features:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Diagnosis_Date_parsed</th>\n",
       "      <th>Diagnosis_Year</th>\n",
       "      <th>Days_Since_Diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-10-21</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>1399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-05-20</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>1918.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-06-15</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>1527.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-10-19</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>3227.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-02-09</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>3480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2024-05-13</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>464.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2017-12-31</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>2789.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2022-12-15</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>979.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2024-03-04</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>534.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2022-10-10</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>1045.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Diagnosis_Date_parsed  Diagnosis_Year  Days_Since_Diagnosis\n",
       "0            2021-10-21          2021.0                1399.0\n",
       "1            2020-05-20          2020.0                1918.0\n",
       "2            2021-06-15          2021.0                1527.0\n",
       "3            2016-10-19          2016.0                3227.0\n",
       "4            2016-02-09          2016.0                3480.0\n",
       "5            2024-05-13          2024.0                 464.0\n",
       "6            2017-12-31          2017.0                2789.0\n",
       "7            2022-12-15          2022.0                 979.0\n",
       "8            2024-03-04          2024.0                 534.0\n",
       "9            2022-10-10          2022.0                1045.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Extract year from diagnosis date\n",
    "df_clean['Diagnosis_Year'] = df_clean['Diagnosis_Date_parsed'].dt.year\n",
    "\n",
    "# Calculate days since diagnosis (relative to most recent date in dataset)\n",
    "ref_date = df_clean['Diagnosis_Date_parsed'].max()\n",
    "if pd.isna(ref_date):\n",
    "    ref_date = pd.to_datetime(\"today\")\n",
    "\n",
    "df_clean['Days_Since_Diagnosis'] = (\n",
    "    ref_date - df_clean['Diagnosis_Date_parsed']\n",
    ").dt.days\n",
    "\n",
    "print(f\"\\nReference date for calculating time since diagnosis: {ref_date.date()}\")\n",
    "print(\"\\nSample of engineered temporal features:\")\n",
    "display(df_clean[['Diagnosis_Date_parsed', 'Diagnosis_Year', 'Days_Since_Diagnosis']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C4Lfdo22czoy"
   },
   "source": [
    "## Step 10: Encode categorical variables\n",
    "\n",
    "Machine learning algorithms require numeric input. Categorical variables must be converted to numbers through **encoding**.\n",
    "\n",
    "### One-hot encoding\n",
    "\n",
    "One-hot encoding creates **binary (0/1) columns** for each category:\n",
    "\n",
    "**Example**: If Diagnosis_Code has values ['DEP', 'OCD', 'ANX']\n",
    "- Creates columns: `Diagnosis_Code_DEP`, `Diagnosis_Code_OCD`, `Diagnosis_Code_ANX`\n",
    "- A patient with 'OCD' gets: [0, 1, 0]\n",
    "\n",
    "**Why use one-hot encoding?**\n",
    "- Treats all categories equally (no implicit ordering)\n",
    "- Works with all ML algorithms\n",
    "- Prevents models from assuming numerical relationships between categories\n",
    "\n",
    "**Alternative**: Label Encoding (1, 2, 3...) should only be used for ordinal data with natural ordering.\n",
    "\n",
    "You'll apply one-hot encoding to Gender, Ethnicity, and Diagnosis_Code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "y-uuawI3czoy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns before encoding:\n",
      "['Patient_ID', 'Age', 'Gender', 'Ethnicity', 'Weight', 'Height_cm', 'Diagnosis_Date', 'Diagnosis_Code', 'Glucose_mg_dL', 'Risk', 'Weight_kg', 'Height_m', 'BMI', 'Diagnosis_Date_parsed', 'Diagnosis_Year', 'Days_Since_Diagnosis']\n",
      "Total columns: 16\n",
      "\n",
      "Columns after encoding:\n",
      "['Patient_ID', 'Age', 'Weight', 'Height_cm', 'Diagnosis_Date', 'Glucose_mg_dL', 'Risk', 'Weight_kg', 'Height_m', 'BMI', 'Diagnosis_Date_parsed', 'Diagnosis_Year', 'Days_Since_Diagnosis', 'Diagnosis_Code_ANX', 'Diagnosis_Code_DEP', 'Diagnosis_Code_OCD', 'Diagnosis_Code_Unknown', 'Gender_Female', 'Gender_Male', 'Gender_Other', 'Gender_Unknown', 'Ethnicity_African', 'Ethnicity_Asian', 'Ethnicity_Caucasian', 'Ethnicity_Hispanic', 'Ethnicity_Unknown']\n",
      "Total columns: 26\n",
      "\n",
      "New encoded columns created: 10\n"
     ]
    }
   ],
   "source": [
    "# Apply one-hot encoding to categorical columns\n",
    "print(\"Columns before encoding:\")\n",
    "print(df_clean.columns.tolist())\n",
    "print(f\"Total columns: {len(df_clean.columns)}\")\n",
    "\n",
    "df_final = pd.get_dummies(\n",
    "    df_clean,\n",
    "    columns=['Diagnosis_Code', 'Gender', 'Ethnicity'],\n",
    "    drop_first=False  # Keep all columns (set True to drop one for linear models)\n",
    ")\n",
    "\n",
    "print(\"\\nColumns after encoding:\")\n",
    "print(df_final.columns.tolist())\n",
    "print(f\"Total columns: {len(df_final.columns)}\")\n",
    "print(f\"\\nNew encoded columns created: {len(df_final.columns) - len(df_clean.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "8WkWgCQxczoy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample of encoded data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient_ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Height_cm</th>\n",
       "      <th>Diagnosis_Date</th>\n",
       "      <th>Glucose_mg_dL</th>\n",
       "      <th>Risk</th>\n",
       "      <th>Weight_kg</th>\n",
       "      <th>Height_m</th>\n",
       "      <th>BMI</th>\n",
       "      <th>...</th>\n",
       "      <th>Diagnosis_Code_Unknown</th>\n",
       "      <th>Gender_Female</th>\n",
       "      <th>Gender_Male</th>\n",
       "      <th>Gender_Other</th>\n",
       "      <th>Gender_Unknown</th>\n",
       "      <th>Ethnicity_African</th>\n",
       "      <th>Ethnicity_Asian</th>\n",
       "      <th>Ethnicity_Caucasian</th>\n",
       "      <th>Ethnicity_Hispanic</th>\n",
       "      <th>Ethnicity_Unknown</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P_new_63</td>\n",
       "      <td>45.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>175.0</td>\n",
       "      <td>2021-10-21</td>\n",
       "      <td>140.0</td>\n",
       "      <td>0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>1.75</td>\n",
       "      <td>27.55</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P016</td>\n",
       "      <td>50.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>165.0</td>\n",
       "      <td>2020-05-20</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>1.65</td>\n",
       "      <td>27.55</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P006</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>165.0</td>\n",
       "      <td>15/06/2021</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.55</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P_new_126</td>\n",
       "      <td>34.0</td>\n",
       "      <td>70</td>\n",
       "      <td>160.0</td>\n",
       "      <td>2016-10-19</td>\n",
       "      <td>110.0</td>\n",
       "      <td>1</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.60</td>\n",
       "      <td>27.34</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P_new_96</td>\n",
       "      <td>25.0</td>\n",
       "      <td>70</td>\n",
       "      <td>180.0</td>\n",
       "      <td>2016-02-09</td>\n",
       "      <td>140.0</td>\n",
       "      <td>0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>21.60</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Patient_ID   Age Weight  Height_cm Diagnosis_Date  Glucose_mg_dL  Risk  \\\n",
       "0   P_new_63  45.0    NaN      175.0     2021-10-21          140.0     0   \n",
       "1       P016  50.0    NaN      165.0     2020-05-20          100.0     0   \n",
       "2       P006  25.0    NaN      165.0     15/06/2021          110.0     0   \n",
       "3  P_new_126  34.0     70      160.0     2016-10-19          110.0     1   \n",
       "4   P_new_96  25.0     70      180.0     2016-02-09          140.0     0   \n",
       "\n",
       "   Weight_kg  Height_m    BMI  ... Diagnosis_Code_Unknown  Gender_Female  \\\n",
       "0       75.0      1.75  27.55  ...                      1              0   \n",
       "1       75.0      1.65  27.55  ...                      0              0   \n",
       "2       75.0       NaN  27.55  ...                      0              1   \n",
       "3       70.0      1.60  27.34  ...                      0              0   \n",
       "4       70.0      1.80  21.60  ...                      0              0   \n",
       "\n",
       "   Gender_Male  Gender_Other  Gender_Unknown  Ethnicity_African  \\\n",
       "0            0             0               1                  0   \n",
       "1            1             0               0                  0   \n",
       "2            0             0               0                  0   \n",
       "3            1             0               0                  0   \n",
       "4            0             0               1                  0   \n",
       "\n",
       "   Ethnicity_Asian  Ethnicity_Caucasian  Ethnicity_Hispanic  Ethnicity_Unknown  \n",
       "0                1                    0                   0                  0  \n",
       "1                0                    0                   0                  1  \n",
       "2                0                    1                   0                  0  \n",
       "3                1                    0                   0                  0  \n",
       "4                1                    0                   0                  0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Preview the encoded dataset\n",
    "print(\"Sample of encoded data:\")\n",
    "display(df_final.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AlRRQ6wDczoy"
   },
   "source": [
    "## Step 11: Scale numeric features\n",
    "\n",
    "### Why scale features?\n",
    "\n",
    "Many machine learning algorithms are sensitive to feature scale:\n",
    "- **Example**: Age (range 0-100) vs Glucose (range 70-500)\n",
    "- Without scaling, algorithms may give more importance to features with larger values\n",
    "- Algorithms affected: Logistic Regression, SVM, KNN, Neural Networks, K-Means\n",
    "- Algorithms NOT affected: Tree-based models (Decision Trees, Random Forest, XGBoost)\n",
    "\n",
    "### StandardScaler (Z-score normalization)\n",
    "\n",
    "**Formula**: z = (x - μ) / σ\n",
    "- Transforms data to have **mean = 0** and **standard deviation = 1**\n",
    "- **Best for**: Algorithms assuming normal distribution (Linear/Logistic Regression, SVM)\n",
    "- **Range**: Typically between -3 and +3 (but unbounded)\n",
    "\n",
    "You'll apply StandardScaler to all numeric features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "T10rU3G3czoy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaling 6 numeric features:\n",
      "['Age', 'Weight_kg', 'Height_cm', 'BMI', 'Glucose_mg_dL', 'Days_Since_Diagnosis']\n"
     ]
    }
   ],
   "source": [
    "# Define numeric columns to scale\n",
    "numeric_cols_to_scale = ['Age', 'Weight_kg', 'Height_cm', 'BMI', 'Glucose_mg_dL', 'Days_Since_Diagnosis']\n",
    "\n",
    "# Filter to only existing columns\n",
    "numeric_cols_existing = [col for col in numeric_cols_to_scale if col in df_final.columns]\n",
    "\n",
    "print(f\"Scaling {len(numeric_cols_existing)} numeric features:\")\n",
    "print(numeric_cols_existing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "MDz2yfhlczoy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verified no missing values before scaling:\n",
      "Age                     0\n",
      "Weight_kg               0\n",
      "Height_cm               0\n",
      "BMI                     0\n",
      "Glucose_mg_dL           0\n",
      "Days_Since_Diagnosis    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Fill any remaining missing values with median before scaling\n",
    "df_final[numeric_cols_existing] = df_final[numeric_cols_existing].fillna(\n",
    "    df_final[numeric_cols_existing].median()\n",
    ")\n",
    "\n",
    "print(\"Verified no missing values before scaling:\")\n",
    "print(df_final[numeric_cols_existing].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "A0boC3oLczoy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaling complete!\n",
      "\n",
      "Scaled features statistics (should have mean≈0, std≈1):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age_scaled</th>\n",
       "      <th>Weight_kg_scaled</th>\n",
       "      <th>Height_cm_scaled</th>\n",
       "      <th>BMI_scaled</th>\n",
       "      <th>Glucose_mg_dL_scaled</th>\n",
       "      <th>Days_Since_Diagnosis_scaled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.980000e+02</td>\n",
       "      <td>1.980000e+02</td>\n",
       "      <td>1.980000e+02</td>\n",
       "      <td>1.980000e+02</td>\n",
       "      <td>1.980000e+02</td>\n",
       "      <td>1.980000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.278439e-16</td>\n",
       "      <td>-6.902447e-16</td>\n",
       "      <td>9.621933e-16</td>\n",
       "      <td>-5.517472e-16</td>\n",
       "      <td>2.607342e-17</td>\n",
       "      <td>-5.382900e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.002535e+00</td>\n",
       "      <td>1.002535e+00</td>\n",
       "      <td>1.002535e+00</td>\n",
       "      <td>1.002535e+00</td>\n",
       "      <td>1.002535e+00</td>\n",
       "      <td>1.002535e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-7.156602e-01</td>\n",
       "      <td>-8.994704e-01</td>\n",
       "      <td>-1.154814e+00</td>\n",
       "      <td>-1.558938e+00</td>\n",
       "      <td>-6.928224e-01</td>\n",
       "      <td>-1.839041e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-5.618235e-01</td>\n",
       "      <td>-7.654141e-01</td>\n",
       "      <td>-4.555688e-01</td>\n",
       "      <td>-4.181248e-01</td>\n",
       "      <td>-5.404692e-01</td>\n",
       "      <td>-7.716356e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-3.738008e-01</td>\n",
       "      <td>-4.234338e-01</td>\n",
       "      <td>-4.555688e-01</td>\n",
       "      <td>-2.198113e-01</td>\n",
       "      <td>-5.404692e-01</td>\n",
       "      <td>-7.427804e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-1.174063e-01</td>\n",
       "      <td>6.025072e-01</td>\n",
       "      <td>9.429215e-01</td>\n",
       "      <td>1.563709e-01</td>\n",
       "      <td>-3.576453e-01</td>\n",
       "      <td>8.161819e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.275609e+00</td>\n",
       "      <td>1.970428e+00</td>\n",
       "      <td>1.642167e+00</td>\n",
       "      <td>2.932759e+00</td>\n",
       "      <td>1.836241e+00</td>\n",
       "      <td>1.912513e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Age_scaled  Weight_kg_scaled  Height_cm_scaled    BMI_scaled  \\\n",
       "count  1.980000e+02      1.980000e+02      1.980000e+02  1.980000e+02   \n",
       "mean   1.278439e-16     -6.902447e-16      9.621933e-16 -5.517472e-16   \n",
       "std    1.002535e+00      1.002535e+00      1.002535e+00  1.002535e+00   \n",
       "min   -7.156602e-01     -8.994704e-01     -1.154814e+00 -1.558938e+00   \n",
       "25%   -5.618235e-01     -7.654141e-01     -4.555688e-01 -4.181248e-01   \n",
       "50%   -3.738008e-01     -4.234338e-01     -4.555688e-01 -2.198113e-01   \n",
       "75%   -1.174063e-01      6.025072e-01      9.429215e-01  1.563709e-01   \n",
       "max    2.275609e+00      1.970428e+00      1.642167e+00  2.932759e+00   \n",
       "\n",
       "       Glucose_mg_dL_scaled  Days_Since_Diagnosis_scaled  \n",
       "count          1.980000e+02                 1.980000e+02  \n",
       "mean           2.607342e-17                -5.382900e-17  \n",
       "std            1.002535e+00                 1.002535e+00  \n",
       "min           -6.928224e-01                -1.839041e+00  \n",
       "25%           -5.404692e-01                -7.716356e-01  \n",
       "50%           -5.404692e-01                -7.427804e-02  \n",
       "75%           -3.576453e-01                 8.161819e-01  \n",
       "max            1.836241e+00                 1.912513e+00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Apply StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaled_columns = [col + '_scaled' for col in numeric_cols_existing]\n",
    "df_final[scaled_columns] = scaler.fit_transform(df_final[numeric_cols_existing])\n",
    "\n",
    "print(\"Scaling complete!\")\n",
    "print(\"\\nScaled features statistics (should have mean≈0, std≈1):\")\n",
    "display(df_final[scaled_columns].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "rP_mAMPUczoz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Comparison of original vs scaled values:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Age_scaled</th>\n",
       "      <th>Glucose_mg_dL</th>\n",
       "      <th>Glucose_mg_dL_scaled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45.0</td>\n",
       "      <td>-0.373801</td>\n",
       "      <td>140.0</td>\n",
       "      <td>-0.357645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50.0</td>\n",
       "      <td>-0.288336</td>\n",
       "      <td>100.0</td>\n",
       "      <td>-0.601410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25.0</td>\n",
       "      <td>-0.715660</td>\n",
       "      <td>110.0</td>\n",
       "      <td>-0.540469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34.0</td>\n",
       "      <td>-0.561823</td>\n",
       "      <td>110.0</td>\n",
       "      <td>-0.540469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25.0</td>\n",
       "      <td>-0.715660</td>\n",
       "      <td>140.0</td>\n",
       "      <td>-0.357645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>25.0</td>\n",
       "      <td>-0.715660</td>\n",
       "      <td>110.0</td>\n",
       "      <td>-0.540469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>45.0</td>\n",
       "      <td>-0.373801</td>\n",
       "      <td>90.0</td>\n",
       "      <td>-0.662352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>60.0</td>\n",
       "      <td>-0.117406</td>\n",
       "      <td>110.0</td>\n",
       "      <td>-0.540469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>45.0</td>\n",
       "      <td>-0.373801</td>\n",
       "      <td>140.0</td>\n",
       "      <td>-0.357645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>45.0</td>\n",
       "      <td>-0.373801</td>\n",
       "      <td>90.0</td>\n",
       "      <td>-0.662352</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age  Age_scaled  Glucose_mg_dL  Glucose_mg_dL_scaled\n",
       "0  45.0   -0.373801          140.0             -0.357645\n",
       "1  50.0   -0.288336          100.0             -0.601410\n",
       "2  25.0   -0.715660          110.0             -0.540469\n",
       "3  34.0   -0.561823          110.0             -0.540469\n",
       "4  25.0   -0.715660          140.0             -0.357645\n",
       "5  25.0   -0.715660          110.0             -0.540469\n",
       "6  45.0   -0.373801           90.0             -0.662352\n",
       "7  60.0   -0.117406          110.0             -0.540469\n",
       "8  45.0   -0.373801          140.0             -0.357645\n",
       "9  45.0   -0.373801           90.0             -0.662352"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compare original vs scaled values\n",
    "print(\"\\nComparison of original vs scaled values:\")\n",
    "comparison_cols = ['Age', 'Age_scaled', 'Glucose_mg_dL', 'Glucose_mg_dL_scaled']\n",
    "display(df_final[comparison_cols].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xv3maHqwczoz"
   },
   "source": [
    "## Step 12: Save the cleaned dataset\n",
    "\n",
    "Now that you've completed all preprocessing steps, you'll save the cleaned dataset to a CSV file. This file is now ready for:\n",
    "- Exploratory data analysis (EDA)\n",
    "- Machine learning model training\n",
    "- Statistical analysis\n",
    "- Sharing with team members (with PII removed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "mwUAEvHdczoz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Cleaned dataset saved to: healthcare_cleaned_data.csv\n",
      "\n",
      "Final dataset shape: 198 rows × 32 columns\n",
      "Original dataset shape: 200 rows × 12 columns\n"
     ]
    }
   ],
   "source": [
    "# Save cleaned dataset\n",
    "output_path = \"healthcare_cleaned_data.csv\"\n",
    "df_final.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"✓ Cleaned dataset saved to: {output_path}\")\n",
    "print(f\"\\nFinal dataset shape: {df_final.shape[0]} rows × {df_final.shape[1]} columns\")\n",
    "print(f\"Original dataset shape: {df.shape[0]} rows × {df.shape[1]} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "I24GXYJQczoz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "File saved in directory: C:\\Users\\sugne\\Documents\\HealthcareData\n"
     ]
    }
   ],
   "source": [
    "# Display working directory\n",
    "import os\n",
    "print(f\"\\nFile saved in directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pRZIFt7cczoz"
   },
   "source": [
    "## Step 13: Evaluate data cleaning results\n",
    "\n",
    "Let's compare the raw and cleaned datasets to verify preprocessing was successful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "9k1ViDJwczoz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "COLUMN COMPARISON\n",
      "============================================================\n",
      "\n",
      "Raw data columns (12):\n",
      "['Patient_ID', 'Age', 'Gender', 'Ethnicity', 'Weight', 'Height_cm', 'Diagnosis_Date', 'Diagnosis_Code', 'Glucose_mg_dL', 'Risk', 'Patient_Name', 'EmailID']\n",
      "\n",
      "Cleaned data columns (16):\n",
      "['Patient_ID', 'Age', 'Gender', 'Ethnicity', 'Weight', 'Height_cm', 'Diagnosis_Date', 'Diagnosis_Code', 'Glucose_mg_dL', 'Risk', 'Weight_kg', 'Height_m', 'BMI', 'Diagnosis_Date_parsed', 'Diagnosis_Year', 'Days_Since_Diagnosis']\n",
      "\n",
      "Final encoded data columns (32):\n",
      "['Patient_ID', 'Age', 'Weight', 'Height_cm', 'Diagnosis_Date', 'Glucose_mg_dL', 'Risk', 'Weight_kg', 'Height_m', 'BMI', 'Diagnosis_Date_parsed', 'Diagnosis_Year', 'Days_Since_Diagnosis', 'Diagnosis_Code_ANX', 'Diagnosis_Code_DEP', 'Diagnosis_Code_OCD', 'Diagnosis_Code_Unknown', 'Gender_Female', 'Gender_Male', 'Gender_Other', 'Gender_Unknown', 'Ethnicity_African', 'Ethnicity_Asian', 'Ethnicity_Caucasian', 'Ethnicity_Hispanic', 'Ethnicity_Unknown', 'Age_scaled', 'Weight_kg_scaled', 'Height_cm_scaled', 'BMI_scaled', 'Glucose_mg_dL_scaled', 'Days_Since_Diagnosis_scaled']\n"
     ]
    }
   ],
   "source": [
    "# Compare column structures\n",
    "print(\"=\"*60)\n",
    "print(\"COLUMN COMPARISON\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nRaw data columns ({len(df.columns)}):\")\n",
    "print(df.columns.tolist())\n",
    "print(f\"\\nCleaned data columns ({len(df_clean.columns)}):\")\n",
    "print(df_clean.columns.tolist())\n",
    "print(f\"\\nFinal encoded data columns ({len(df_final.columns)}):\")\n",
    "print(df_final.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "ZaIOkUTvczoz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "MISSING VALUES COMPARISON\n",
      "============================================================\n",
      "\n",
      "Raw data missing values:\n",
      "Patient_ID         0\n",
      "Age               28\n",
      "Gender            38\n",
      "Ethnicity         35\n",
      "Weight            44\n",
      "Height_cm         40\n",
      "Diagnosis_Date    10\n",
      "Diagnosis_Code    33\n",
      "Glucose_mg_dL     42\n",
      "Risk               0\n",
      "Patient_Name       0\n",
      "EmailID            0\n",
      "dtype: int64\n",
      "\n",
      "Total missing values in raw data: 270\n",
      "\n",
      "Cleaned data missing values:\n",
      "Patient_ID                0\n",
      "Age                       0\n",
      "Gender                    0\n",
      "Ethnicity                 0\n",
      "Weight                   43\n",
      "Height_cm                 0\n",
      "Diagnosis_Date           10\n",
      "Diagnosis_Code            0\n",
      "Glucose_mg_dL             0\n",
      "Risk                      0\n",
      "Weight_kg                 0\n",
      "Height_m                 39\n",
      "BMI                       0\n",
      "Diagnosis_Date_parsed    10\n",
      "Diagnosis_Year           10\n",
      "Days_Since_Diagnosis     10\n",
      "dtype: int64\n",
      "\n",
      "Total missing values in cleaned data: 122\n"
     ]
    }
   ],
   "source": [
    "# Compare missing values\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MISSING VALUES COMPARISON\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nRaw data missing values:\")\n",
    "print(df.isna().sum())\n",
    "print(f\"\\nTotal missing values in raw data: {df.isna().sum().sum()}\")\n",
    "\n",
    "print(\"\\nCleaned data missing values:\")\n",
    "print(df_clean.isna().sum())\n",
    "print(f\"\\nTotal missing values in cleaned data: {df_clean.isna().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "hk6JOVXeczo0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "STATISTICAL SUMMARY COMPARISON\n",
      "============================================================\n",
      "\n",
      "Raw data summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Height_cm</th>\n",
       "      <th>Glucose_mg_dL</th>\n",
       "      <th>Risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>172.000000</td>\n",
       "      <td>160.000000</td>\n",
       "      <td>158.000000</td>\n",
       "      <td>200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>70.087209</td>\n",
       "      <td>169.031250</td>\n",
       "      <td>220.981013</td>\n",
       "      <td>0.465000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>62.340026</td>\n",
       "      <td>7.780335</td>\n",
       "      <td>177.443324</td>\n",
       "      <td>0.500025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>25.000000</td>\n",
       "      <td>160.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>34.000000</td>\n",
       "      <td>160.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>45.000000</td>\n",
       "      <td>165.000000</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>60.000000</td>\n",
       "      <td>175.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>200.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Age   Height_cm  Glucose_mg_dL        Risk\n",
       "count  172.000000  160.000000     158.000000  200.000000\n",
       "mean    70.087209  169.031250     220.981013    0.465000\n",
       "std     62.340026    7.780335     177.443324    0.500025\n",
       "min     25.000000  160.000000      85.000000    0.000000\n",
       "25%     34.000000  160.000000      90.000000    0.000000\n",
       "50%     45.000000  165.000000     110.000000    0.000000\n",
       "75%     60.000000  175.000000     500.000000    1.000000\n",
       "max    200.000000  180.000000     500.000000    1.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cleaned data summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Height_cm</th>\n",
       "      <th>Glucose_mg_dL</th>\n",
       "      <th>Risk</th>\n",
       "      <th>Weight_kg</th>\n",
       "      <th>Height_m</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Diagnosis_Year</th>\n",
       "      <th>Days_Since_Diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>198.000000</td>\n",
       "      <td>198.000000</td>\n",
       "      <td>198.000000</td>\n",
       "      <td>198.000000</td>\n",
       "      <td>198.000000</td>\n",
       "      <td>159.000000</td>\n",
       "      <td>198.000000</td>\n",
       "      <td>188.000000</td>\n",
       "      <td>188.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>66.868687</td>\n",
       "      <td>168.257576</td>\n",
       "      <td>198.686869</td>\n",
       "      <td>0.469697</td>\n",
       "      <td>81.190909</td>\n",
       "      <td>1.690566</td>\n",
       "      <td>28.625152</td>\n",
       "      <td>2020.319149</td>\n",
       "      <td>1768.047872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>58.651885</td>\n",
       "      <td>7.168694</td>\n",
       "      <td>164.508321</td>\n",
       "      <td>0.500346</td>\n",
       "      <td>14.657786</td>\n",
       "      <td>0.077983</td>\n",
       "      <td>4.903646</td>\n",
       "      <td>2.737002</td>\n",
       "      <td>987.003450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>25.000000</td>\n",
       "      <td>160.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>68.040000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>2015.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>34.000000</td>\n",
       "      <td>165.000000</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>26.580000</td>\n",
       "      <td>2018.000000</td>\n",
       "      <td>957.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>45.000000</td>\n",
       "      <td>165.000000</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>1.650000</td>\n",
       "      <td>27.550000</td>\n",
       "      <td>2020.000000</td>\n",
       "      <td>1693.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>60.000000</td>\n",
       "      <td>175.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>29.390000</td>\n",
       "      <td>2023.000000</td>\n",
       "      <td>2576.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>200.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>42.970000</td>\n",
       "      <td>2025.000000</td>\n",
       "      <td>3599.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Age   Height_cm  Glucose_mg_dL        Risk   Weight_kg  \\\n",
       "count  198.000000  198.000000     198.000000  198.000000  198.000000   \n",
       "mean    66.868687  168.257576     198.686869    0.469697   81.190909   \n",
       "std     58.651885    7.168694     164.508321    0.500346   14.657786   \n",
       "min     25.000000  160.000000      85.000000    0.000000   68.040000   \n",
       "25%     34.000000  165.000000     110.000000    0.000000   70.000000   \n",
       "50%     45.000000  165.000000     110.000000    0.000000   75.000000   \n",
       "75%     60.000000  175.000000     140.000000    1.000000   90.000000   \n",
       "max    200.000000  180.000000     500.000000    1.000000  110.000000   \n",
       "\n",
       "         Height_m         BMI  Diagnosis_Year  Days_Since_Diagnosis  \n",
       "count  159.000000  198.000000      188.000000            188.000000  \n",
       "mean     1.690566   28.625152     2020.319149           1768.047872  \n",
       "std      0.077983    4.903646        2.737002            987.003450  \n",
       "min      1.600000   21.000000     2015.000000              0.000000  \n",
       "25%      1.600000   26.580000     2018.000000            957.250000  \n",
       "50%      1.650000   27.550000     2020.000000           1693.000000  \n",
       "75%      1.750000   29.390000     2023.000000           2576.250000  \n",
       "max      1.800000   42.970000     2025.000000           3599.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compare statistical summaries\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STATISTICAL SUMMARY COMPARISON\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nRaw data summary:\")\n",
    "display(df.describe())\n",
    "\n",
    "print(\"\\nCleaned data summary:\")\n",
    "display(df_clean.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "GroAtaD1czo0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "CATEGORICAL STANDARDIZATION - GENDER EXAMPLE\n",
      "============================================================\n",
      "\n",
      "Raw Gender value counts:\n",
      "M         46\n",
      "F         40\n",
      "NaN       38\n",
      "Female    36\n",
      "Male      33\n",
      "Other      7\n",
      "Name: Gender, dtype: int64\n",
      "\n",
      "Cleaned Gender value counts:\n",
      "Male       79\n",
      "Female     74\n",
      "Unknown    38\n",
      "Other       7\n",
      "Name: Gender, dtype: int64\n",
      " Successfully standardized from 6 variations to 4 consistent categories!\n"
     ]
    }
   ],
   "source": [
    "# Compare categorical standardization (Gender example)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CATEGORICAL STANDARDIZATION - GENDER EXAMPLE\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nRaw Gender value counts:\")\n",
    "print(df['Gender'].value_counts(dropna=False))\n",
    "\n",
    "print(\"\\nCleaned Gender value counts:\")\n",
    "print(df_clean['Gender'].value_counts(dropna=False))\n",
    "\n",
    "print(\" Successfully standardized from 6 variations to 4 consistent categories!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mitY5dKrczo0"
   },
   "source": [
    "\n",
    "\n",
    "# Exercises\n",
    "\n",
    "Now it's your turn! Apply what you've learned to a new synthetic healthcare dataset. The following exercises will test your understanding of the data preprocessing pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "daTcGsvzczo0"
   },
   "source": [
    "## Exercise 1: Load and prepare data\n",
    "\n",
    "Load the `synthetic_data.csv` file into a DataFrame and create a clean working copy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "9D1vc0Naczo0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows of the dataset:\n"
     ]
    }
   ],
   "source": [
    "# your code goes here\n",
    "# Load the raw healthcare data from CSV file\n",
    "df = pd.read_csv(\"https://foundations-of-healthcare-data-analytics-4e579d.gitlab.io/labs/Cleaning_and_Validating_Healthcare_Data_Using_Python/synthetic_data.csv\")\n",
    "\n",
    "# Display the first few rows to get an initial sense of the data\n",
    "print(\"First 5 rows of the dataset:\")\n",
    "df.head()\n",
    "\n",
    "# Create a working copy\n",
    "df_clean = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IvWDDhKtczo0"
   },
   "source": [
    "<details>\n",
    "    <summary>Click here for a hint</summary>\n",
    "    \n",
    "Use the `read_csv()` function to load the data, then use `.copy()` to create a working copy. Reference **Step 1** for the exact syntax.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ktLaWds-czo1"
   },
   "source": [
    "<details>\n",
    "    <summary>Click here for solution</summary>\n",
    "\n",
    "```python\n",
    "# Load the synthetic healthcare data\n",
    "df = pd.read_csv(\"https://foundations-of-healthcare-data-analytics-4e579d.gitlab.io/labs/Cleaning_and_Validating_Healthcare_Data_Using_Python/synthetic_data.csv\")\n",
    "\n",
    "# Create a working copy\n",
    "df_clean = df.copy()\n",
    "\n",
    "# Display column names to verify\n",
    "print(\"Columns in dataset:\")\n",
    "print(df_clean.columns.tolist())\n",
    "print(f\"\\nDataset loaded: {df_clean.shape[0]} rows × {df_clean.shape[1]} columns\")\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yIJ0hm22czo1"
   },
   "source": [
    "## Exercise 2: Remove personal data\n",
    "\n",
    "Identify and remove all PII (Personally Identifiable Information) columns from the dataset. Common PII includes: Patient_ID, Name, Address, Phone, Email."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "RulLbFQfczo1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing PII columns: ['Patient_Name', 'EmailID']\n",
      "\n",
      "Columns after removing PII:\n",
      "['Patient_ID', 'Age', 'Gender', 'Ethnicity', 'Weight', 'Height_cm', 'Diagnosis_Date', 'Diagnosis_Code', 'Glucose_mg_dL', 'Risk']\n",
      "\n",
      "Reduced from 12 to 10 columns\n"
     ]
    }
   ],
   "source": [
    "# your code goes here\n",
    "# Identify and remove PII columns\n",
    "pii_columns = ['Patient_Name', 'EmailID']\n",
    "print(f\"Removing PII columns: {pii_columns}\")\n",
    "\n",
    "df_clean = df_clean.drop(columns=pii_columns, errors='ignore')\n",
    "\n",
    "print(\"\\nColumns after removing PII:\")\n",
    "print(df_clean.columns.tolist())\n",
    "print(f\"\\nReduced from {len(df.columns)} to {len(df_clean.columns)} columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aYzRETXdczo1"
   },
   "source": [
    "<details>\n",
    "    <summary>Click here for a hint</summary>\n",
    "    \n",
    "Use the `.drop()` method with `columns` parameter. Set `errors='ignore'` to avoid errors if a column doesn't exist. Reference **Step 4** for the syntax.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tXH26-m3czo1"
   },
   "source": [
    "<details>\n",
    "    <summary>Click here for solution</summary>\n",
    "\n",
    "```python\n",
    "# Define PII columns to remove\n",
    "pii_cols = ['Patient_ID', 'Name', 'Address', 'Phone', 'Email']\n",
    "\n",
    "# Remove PII columns (only if they exist)\n",
    "df_clean = df_clean.drop(\n",
    "    columns=[col for col in pii_cols if col in df_clean.columns],\n",
    "    errors='ignore'\n",
    ")\n",
    "\n",
    "print(\"After removing PII columns:\")\n",
    "print(df_clean.columns.tolist())\n",
    "print(f\"\\nColumns remaining: {len(df_clean.columns)}\")\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L7Ia56veczo1"
   },
   "source": [
    "## Exercise 3: Drop duplicate rows\n",
    "\n",
    "Check for and remove any duplicate rows in the dataset. Report how many duplicates were found and removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "UgeMVAJwczo1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows before: 198\n",
      "rows after: 198\n",
      "rows removed :0\n"
     ]
    }
   ],
   "source": [
    "# your code goes here\n",
    "# Check for duplicate rows\n",
    "rows_before=len(df_clean)\n",
    "print(f\"rows before: {rows_before}\")\n",
    "\n",
    "# Remove exact duplicate rows (keep first occurrence)\n",
    "df_clean = df_clean.drop_duplicates(keep='first')\n",
    "\n",
    "# Count rows after deduplication\n",
    "rows_after = len(df_clean)\n",
    "print(f\"rows after: {rows_after}\")\n",
    "\n",
    "rows_removed=rows_before-rows_after\n",
    "print(f\"rows removed :{rows_removed}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Azym-_AWczo2"
   },
   "source": [
    "<details>\n",
    "    <summary>Click here for a hint</summary>\n",
    "    \n",
    "Use `.drop_duplicates()` method with `keep='first'` parameter. Count rows before and after to see how many were removed. Reference **Step 5**.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iHyEPt7lczo2"
   },
   "source": [
    "<details>\n",
    "    <summary>Click here for solution</summary>\n",
    "\n",
    "```python\n",
    "# Count rows before deduplication\n",
    "rows_before = len(df_clean)\n",
    "\n",
    "# Remove exact duplicate rows (keep first occurrence)\n",
    "df_clean = df_clean.drop_duplicates(keep='first')\n",
    "\n",
    "# Count rows after deduplication\n",
    "rows_after = len(df_clean)\n",
    "\n",
    "# Report results\n",
    "print(f\"Rows before deduplication: {rows_before}\")\n",
    "print(f\"Rows after deduplication: {rows_after}\")\n",
    "print(f\"Duplicate rows removed: {rows_before - rows_after}\")\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XUyqwmRbczo2"
   },
   "source": [
    "## Exercise 4: Handle missing values in numeric columns\n",
    "\n",
    "Identify all numeric columns, check for missing values, and impute them using the median strategy. Verify that all missing values have been filled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "piZM63XEczo2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Age', 'Height_cm', 'Glucose_mg_dL', 'Risk']\n",
      "Age               28\n",
      "Gender            38\n",
      "Ethnicity         35\n",
      "Weight            43\n",
      "Height_cm         39\n",
      "Diagnosis_Date    10\n",
      "Diagnosis_Code    32\n",
      "Glucose_mg_dL     42\n",
      "Risk               0\n",
      "dtype: int64\n",
      "Imputed Age with median = 45.0\n",
      "Imputed Gender with median = nan\n",
      "Imputed Ethnicity with median = nan\n",
      "Imputed Weight with median = 90.0\n",
      "Imputed Height_cm with median = 165.0\n",
      "Imputed Diagnosis_Date with median = nan\n",
      "Imputed Diagnosis_Code with median = nan\n",
      "Imputed Glucose_mg_dL with median = 110.0\n",
      "Imputed Risk with median = 0.0\n",
      "\n",
      "Missing values after imputation:\n",
      "Age                 0\n",
      "Gender            198\n",
      "Ethnicity         198\n",
      "Weight              0\n",
      "Height_cm           0\n",
      "Diagnosis_Date    198\n",
      "Diagnosis_Code    198\n",
      "Glucose_mg_dL       0\n",
      "Risk                0\n",
      "dtype: int64\n",
      "\n",
      "✓ All numeric missing values imputed successfully!\n"
     ]
    }
   ],
   "source": [
    "# your code goes here\n",
    "# Check missing values before imputation\n",
    "\n",
    "number_cols=df_clean.select_dtypes(include=[np.number]).columns.tolist()\n",
    "print(number_cols)\n",
    "\n",
    "print(df_clean[numeric_cols].isnull().sum())\n",
    "\n",
    "# Convert to numeric (coerce invalid values to NaN)\n",
    "for col in numeric_cols:\n",
    "    df_clean[col] = pd.to_numeric(df_clean[col], errors='coerce')\n",
    "\n",
    "# Median imputation\n",
    "for col in numeric_cols:\n",
    "    median_val = df_clean[col].median()\n",
    "    df_clean[col] = df_clean[col].fillna(median_val)\n",
    "    print(f\"Imputed {col} with median = {median_val}\")\n",
    "\n",
    "# Verify\n",
    "print(\"\\nMissing values after imputation:\")\n",
    "print(df_clean[numeric_cols].isnull().sum())\n",
    "print(\"\\n✓ All numeric missing values imputed successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L2ReZnP5czo2"
   },
   "source": [
    "<details>\n",
    "    <summary>Click here for a hint</summary>\n",
    "    \n",
    "First, use `.select_dtypes(include=[np.number])` to get numeric columns. Then use `.median()` and `.fillna()` for each column. Reference **Step 8** for the complete approach.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iP-omGb5czo2"
   },
   "source": [
    "<details>\n",
    "    <summary>Click here for solution</summary>\n",
    "\n",
    "```python\n",
    "# Identify numeric columns\n",
    "numeric_cols = df_clean.select_dtypes(include=[np.number]).columns.tolist()\n",
    "print(f\"Numeric columns found: {numeric_cols}\")\n",
    "\n",
    "# Check missing values before imputation\n",
    "print(\"\\nMissing values before imputation:\")\n",
    "print(df_clean[numeric_cols].isnull().sum())\n",
    "\n",
    "# Convert to numeric (coerce invalid values to NaN)\n",
    "for col in numeric_cols:\n",
    "    df_clean[col] = pd.to_numeric(df_clean[col], errors='coerce')\n",
    "\n",
    "# Median imputation\n",
    "for col in numeric_cols:\n",
    "    median_val = df_clean[col].median()\n",
    "    df_clean[col] = df_clean[col].fillna(median_val)\n",
    "    print(f\"Imputed {col} with median = {median_val}\")\n",
    "\n",
    "# Verify\n",
    "print(\"\\nMissing values after imputation:\")\n",
    "print(df_clean[numeric_cols].isnull().sum())\n",
    "print(\"\\n✓ All numeric missing values imputed successfully!\")\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OilPY2Gfczo2"
   },
   "source": [
    "## Exercise 5: Standardize categorical variables\n",
    "\n",
    "Standardize the inconsistent categorical entries in the `Gender` and `Disease_Type` columns. Print the unique values before and after standardization.\n",
    "\n",
    "**Hint**: Gender variations might include: M/Male/m/F/Female/f  \n",
    "**Hint**: Disease_Type variations might include: ckd/CKD, LD/ld/Liver Disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "Hjf1FhGDczo2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "CATEGORICAL STANDARDIZATION - GENDER EXAMPLE\n",
      "============================================================\n",
      "\n",
      "Raw Gender value counts:\n",
      "M         46\n",
      "F         40\n",
      "NaN       38\n",
      "Female    36\n",
      "Male      33\n",
      "Other      7\n",
      "Name: Gender, dtype: int64\n",
      "\n",
      "Cleaned Gender value counts:\n",
      "NaN    198\n",
      "Name: Gender, dtype: int64\n",
      "Before standardization - Gender unique values:\n",
      "NaN    198\n",
      "Name: Gender, dtype: int64\n",
      "\n",
      "After standardization - Gender unique values:\n",
      "NaN    198\n",
      "Name: Gender, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Compare categorical standardization (Gender example)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CATEGORICAL STANDARDIZATION - GENDER EXAMPLE\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nRaw Gender value counts:\")\n",
    "print(df['Gender'].value_counts(dropna=False))\n",
    "\n",
    "print(\"\\nCleaned Gender value counts:\")\n",
    "print(df_clean['Gender'].value_counts(dropna=False))\n",
    "\n",
    "\n",
    "# Standardize Gender column\n",
    "print(\"Before standardization - Gender unique values:\")\n",
    "print(df_clean['Gender'].value_counts(dropna=False))\n",
    "\n",
    "# Convert to lowercase and strip whitespace for consistent matching\n",
    "df_clean['Gender'] = df_clean['Gender'].astype(str).str.strip().str.lower()\n",
    "\n",
    "# Define mapping for known variations\n",
    "gender_map = {\n",
    "    'male': 'Male', 'm': 'Male',\n",
    "    'female': 'Female', 'f': 'Female',\n",
    "    'other': 'Other',\n",
    "    'nan': np.nan, 'none': np.nan\n",
    "}\n",
    "\n",
    "# Apply mapping\n",
    "df_clean['Gender'] = df_clean['Gender'].replace({'nan': np.nan})\n",
    "df_clean['Gender'] = df_clean['Gender'].map(\n",
    "    lambda x: gender_map.get(x, x.capitalize() if pd.notna(x) else x)\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nAfter standardization - Gender unique values:\")\n",
    "print(df_clean['Gender'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z-kgnujyczo2"
   },
   "source": [
    "1<details>\n",
    "    <summary>Click here for a hint</summary>\n",
    "    \n",
    "Use `.str.lower()` and `.str.strip()` first, then create a mapping dictionary to standardize variations. Reference **Step 6** for the complete pattern.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uTcxy07Tczo2"
   },
   "source": [
    "<details>\n",
    "    <summary>Click here for solution</summary>\n",
    "\n",
    "```python\n",
    "# Standardize Gender\n",
    "print(\"Before standardization - Gender:\")\n",
    "print(df_clean['Gender'].value_counts(dropna=False))\n",
    "\n",
    "df_clean['Gender'] = df_clean['Gender'].astype(str).str.strip().str.lower()\n",
    "gender_map = {\n",
    "    'male': 'Male', 'm': 'Male',\n",
    "    'female': 'Female', 'f': 'Female',\n",
    "    'other': 'Other',\n",
    "    'nan': np.nan, 'none': np.nan\n",
    "}\n",
    "df_clean['Gender'] = df_clean['Gender'].replace({'nan': np.nan})\n",
    "df_clean['Gender'] = df_clean['Gender'].map(\n",
    "    lambda x: gender_map.get(x, x.capitalize() if pd.notna(x) else x)\n",
    ")\n",
    "\n",
    "print(\"\\nAfter standardization - Gender:\")\n",
    "print(df_clean['Gender'].value_counts(dropna=False))\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wUhcMA8Wczo2"
   },
   "source": [
    "---\n",
    "\n",
    "# Congratulations!\n",
    "\n",
    "You have successfully completed this lab on healthcare data preprocessing! You've learned how to systematically clean messy real-world data by handling missing values, removing duplicates, standardizing inconsistent entries, engineering meaningful features, and preparing data for machine learning. These skills are essential for any data science project, especially in healthcare where data quality directly impacts patient outcomes and model reliability.\n",
    "\n",
    "## Authors\n",
    "\n",
    "[Ramesh Sannareddy](https://www.linkedin.com/in/rsannareddy/)\n",
    "\n",
    "Copyright © 2025 SkillUp. All rights reserved."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
